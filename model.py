import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
import warnings
warnings.filterwarnings('ignore')

# ç¼–ç æ£€æµ‹ï¼šè§£å†³ä¸­æ–‡æ–‡ä»¶è¯»å–é—®é¢˜
def detect_file_encoding(file_path):
    common_encodings = ['gbk', 'gb2312', 'utf-8', 'latin-1']
    for encoding in common_encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                f.readline()
            return encoding
        except UnicodeDecodeError:
            continue
    raise ValueError("æœªæ£€æµ‹åˆ°æ”¯æŒçš„ç¼–ç æ ¼å¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§")

# åŠ è½½æ•°æ®ï¼šç›®æ ‡åˆ—å›ºå®šä¸ºâ€œæœŸæœ«è€ƒè¯•åˆ†æ•°â€
def load_and_preprocess_data():
    file_path = "student_data_adjusted_rounded.csv"
    encoding = detect_file_encoding(file_path)
    df = pd.read_csv(file_path, encoding=encoding)
    
    # ç›®æ ‡åˆ—ï¼šæ ¹æ®ä½ çš„CSVå®é™…åˆ—åè®¾ç½®ä¸ºâ€œæœŸæœ«è€ƒè¯•åˆ†æ•°â€
    target = "æœŸæœ«è€ƒè¯•åˆ†æ•°"
    print(f"âœ… ç¡®è®¤ç›®æ ‡åˆ—ï¼š{target}")
    
    # æ’é™¤éç‰¹å¾åˆ—ï¼ˆå­¦å·ã€å§“åï¼‰ï¼Œé¿å…å¹²æ‰°æ¨¡å‹
    exclude_cols = [target, "å­¦å·", "å§“å"]
    X = df.drop([col for col in exclude_cols if col in df.columns], axis=1)
    y = df[target]  # æ­¤æ—¶ä¸ä¼šæŠ¥KeyErrorï¼Œåˆ—åå®Œå…¨åŒ¹é…
    
    # ç¼–ç åˆ†ç±»ç‰¹å¾ï¼ˆå¦‚æ€§åˆ«ã€ä¸“ä¸šç­‰ï¼‰
    categorical_cols = X.select_dtypes(include=["object", "category"]).columns.tolist()
    print(f"ğŸ”§ åˆ†ç±»ç‰¹å¾ï¼š{categorical_cols}")
    X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
    
    print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆï¼š{X.shape[0]} ä¸ªæ ·æœ¬ï¼Œ{X.shape[1]} ä¸ªç‰¹å¾")
    return X, y, df, target

# è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
def train_and_save_model():
    X, y, df, target = load_and_preprocess_data()
    
    # åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # åˆå§‹åŒ–éšæœºæ£®æ—æ¨¡å‹ï¼ˆé€‚é…æ•™è‚²æ•°æ®çš„å‚æ•°ï¼‰
    model = RandomForestRegressor(
        n_estimators=120,  # æ ‘çš„æ•°é‡
        max_depth=10,      # æœ€å¤§æ·±åº¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        min_samples_split=5,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # æ¨¡å‹è¯„ä¼°
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)  # å¹³å‡ç»å¯¹è¯¯å·®
    r2 = r2_score(y_test, y_pred)              # å†³å®šç³»æ•°ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰
    print(f"\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
    print(f"   - å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ï¼š{mae:.2f} åˆ†")
    print(f"   - å†³å®šç³»æ•°ï¼ˆRÂ²ï¼‰ï¼š{r2:.4f}")
    
    # ä¿å­˜æ¨¡å‹å’Œå…³é”®é…ç½®ï¼ˆä¾›Streamlitè°ƒç”¨ï¼‰
    joblib.dump(model, "student_score_model.pkl")  # æ¨¡å‹æ–‡ä»¶
    joblib.dump(X.columns.tolist(), "model_feature_names.pkl")  # ç‰¹å¾åˆ—è¡¨
    joblib.dump(df["ä¸“ä¸š"].unique().tolist(), "unique_majors.pkl")  # ä¸“ä¸šåˆ—è¡¨
    joblib.dump(target, "target_column_name.pkl")  # ç›®æ ‡åˆ—åï¼ˆé¿å…åç»­ç¡¬ç¼–ç ï¼‰
    print(f"\nğŸ’¾ æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜ï¼š")
    print(f"   - student_score_model.pklï¼ˆæ ¸å¿ƒæ¨¡å‹ï¼‰")
    print(f"   - model_feature_names.pklï¼ˆç‰¹å¾åˆ—è¡¨ï¼‰")
    print(f"   - unique_majors.pklï¼ˆä¸“ä¸šåˆ—è¡¨ï¼‰")

if __name__ == "__main__":
    train_and_save_model()
